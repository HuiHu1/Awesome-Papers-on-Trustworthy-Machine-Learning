This repository aims to collect awesome papers or talks on trustworthy machine learning (including paper links, and code links).

#### Survey
1. Differential Privacy and Machine Learning - A Survey and Review (arXiv preprint 2014)[[Paper]](https://arxiv.org/pdf/1412.7584.pdf). 
2. A Survey on Security Threats and Defensive techniques of Machine Learning a data driven perspective (IEEE access 2018)[[Paper]](https://ieeexplore.ieee.org/abstract/document/8290925). 
3. When Machine Learning Meets Privacy: A Survey and Outlook (ACM Computing 2020)[[Paper]](https://arxiv.org/pdf/2011.11819.pdf).
4. A Survey on Privacy in Social Media: Identification, Mitigation, and Applications (ACM Transactions on Data Science 2020)[[Paper]](https://dl.acm.org/doi/pdf/10.1145/3343038).
5. Security of Neural Networks from Hardware Perspective: A Survey and Beyond (ASP-DAC 2021)[[Paper]](https://ieeexplore.ieee.org/abstract/document/9371637?casa_token=mjuDN_p4zlEAAAAA:1M--ahNOyo5OILtsqSFoycdzTqWqJg44fgFFTtyxNMaWG5mHrxRYaw9jbXc5ffUhpIVJBWLraw).
6. Trustworthy Graph Learning: Reliability, Explainability, and Privacy Protection (KDD 2022)[[Paper]](https://dl.acm.org/doi/pdf/10.1145/3534678.3542597?casa_token=pwDMMKIOSJUAAAAA:nN-GrlX_rUS-9RpmZv6Y0kwp3ZNV8X2GTWtBr_DW0S93tG8IafiRxRKGktW4i1ShH8hDwzUw-X8c).
7. A Survey on Privacy in Graph Neural Networks: Attacks, Preservation, and Applications (arXiv preprint 2023)[[Paper]](https://arxiv.org/pdf/2308.16375.pdf). 

#### Fairness
1. Flexibly Fair Representation Learning by Disentanglement (ICML 2019)[[Paper]](https://arxiv.org/pdf/1906.02589.pdf).
2. On Structural Explanation of Bias in Graph Neural Networks (KDD 2022)[[Paper]](https://arxiv.org/pdf/2206.12104.pdf)[[Code]](https://github.com/yushundong/REFEREE).
3. Avoiding Biases due to Similarity Assumptions in Node Embeddings (KDD 2022)[[Paper]](https://faculty.mccombs.utexas.edu/deepayan.chakrabarti/mywww/papers/kdd22-avoiding.pdf).
4. Learning Fair Representation via Distributional Contrastive Disentanglement (KDD 2022)[[Paper]](https://dl.acm.org/doi/pdf/10.1145/3534678.3539232?casa_token=JaW7DTi1U9gAAAAA:Vcck-pl6AK_9-hbuMe3qfTkjPx4Mal0jD4VvdHcYKYCxbuEkshkrUpb9J1wXZjfD5FWwe8Af8XTa).
5. Algorithmic Fairness on Graphs: Methods and Trends (KDD 2022)[[Paper]](https://dl.acm.org/doi/abs/10.1145/3534678.3542599).
6. Algorithmic Fairness Verification with Graphical Models (AAAI 2022)[[Paper]](https://www.aaai.org/AAAI22Papers/AAAI-4695.GhoshB.pdf).
7. Improving Fairness in Graph Neural Networks via Mitigating Sensitive Attribute Leakage (KDD 2022)[[Paper]](https://arxiv.org/pdf/2206.03426.pdf)[[Code]](https://github.com/YuWVandy/FairVGNN).
8. EDITS: Modeling and Mitigating Data Bias for Graph Neural Networks (WWW 2022)[[Paper]](https://arxiv.org/pdf/2108.05233.pdf)[[Code]](https://github.com/yushundong/EDITS).
9. Achieving Fairness at No Utility Cost via Data Reweighing with Influence (ICML 2022)[[Paper]](https://arxiv.org/pdf/2202.00787.pdf)[[Code]](https://github.com/brandeis-machine-learning/influence-fairness).
10. Debiasing Graph Neural Networks via Learning Disentangled Causal Substructure (NeurIPS 2022)[[Paper]](https://arxiv.org/pdf/2209.14107.pdf)[[Code]](https://github.com/googlebaba/DisC).
11. Self-Supervised Fair Representation Learning without Demographics (NeurIPS 2022)[[Paper]](https://openreview.net/pdf?id=7TGpLKADODE).
12. Pushing the limits of fairness impossibility: Who's the fairest of them all? (NeurIPS 2022)[[Paper]](https://openreview.net/pdf?id=bot35zOudq).
13. Uncovering the Structural Fairness in Graph Contrastive Learning (NeurIPS 2022)[[Paper]](https://openreview.net/pdf?id=RJemsN3V_kt).
14. Feature-Level Debiased Natural Language Understanding (AAAI 2023)[[Paper]](https://arxiv.org/pdf/2212.05421.pdf)[[Code]](https://github.com/youganglyu/DCT).

#### Privacy (Attacks and Defenses)
1. Adversarial Attacks on Graph Neural Networks via Meta-Learning (ICLR 2019)[[Paper]](https://arxiv.org/pdf/1902.08412.pdf) [[Code]](https://github.com/danielzuegner/gnn-meta-attack).
2. Alleviating Privacy Attacks via Causal Learning (ICML 2020)[[Paper]](http://proceedings.mlr.press/v119/tople20a/tople20a.pdf).
3. Information Obfuscation of Graph Neural Networks (ICML 2021)[[Paper]](https://arxiv.org/pdf/2009.13504.pdf).
4. How Does Data Augmentation Affect Privacy in Machine Learning? (AAAI 2021)[[Paper]](https://arxiv.org/pdf/2007.10567.pdf).
5. Graph Embedding for Recommendation against Attribute Inference Attacks (WWW 2021)[[Paper]](https://arxiv.org/pdf/2101.12549.pdf)).
6. DICE: Domain-attack Invariant Causal Learning for Improved Data Privacy Protection and Adversarial Robustness (KDD 2022)[[Paper]](https://dl.acm.org/doi/abs/10.1145/3534678.3539242).
7. PrivateSNN: Privacy-Preserving Spiking Neural Networks (AAAI 2022)[[Paper]](https://arxiv.org/abs/2104.03414).
8. Subspace Differential Privacy (AAAI 2022)[[Paper]](https://arxiv.org/abs/2108.11527).
9. Masked Autoencoders Are Scalable Vision Learners (CVPR 2022)[[Paper]](https://openaccess.thecvf.com/content/CVPR2022/papers/He_Masked_Autoencoders_Are_Scalable_Vision_Learners_CVPR_2022_paper.pdf).
10. GraphMAE: Self-Supervised Masked Graph Autoencoders (KDD 2022)[[Paper]](https://arxiv.org/pdf/2205.10803.pdf) [[Code]](https://github.com/THUDM/GraphMAE).
11. ConfounderGAN: Protecting Image Data Privacy with Causal Confounder (NeurIPS 2022)[[Paper]](https://openreview.net/pdf?id=XxmOKCt8dO9).
12. Unnoticeable Backdoor Attacks on Graph Neural Networks (WWW 2023)[[Paper]](https://arxiv.org/pdf/2303.01263.pdf).
13. FaceMAE: Privacy-Preserving Face Recognition via Masked Autoencoders (ICLR 2023)[[Paper]](https://arxiv.org/pdf/2205.11090.pdf) [[Code]](https://github.com/kaiwang960112/FaceMAE).

#### Interpretability
1. GNNExplainer: Generating Explanations for Graph Neural Networks (NeurIPS 2019)[[Paper]](https://arxiv.org/pdf/1903.03894.pdf)[[Code]](https://github.com/RexYing/gnn-model-explainer).  
2. Concept Whitening for Interpretable Image Recognition (Nature Machine Intelligence 2020)[[Paper]](https://arxiv.org/pdf/2002.01650.pdf,https://github.com/danielzuegner/gnn-meta-attack).
3. Explaining Machine Learning Predictions: State-of-the-art, Challenges, Opportunities (NeurIPS 2020)[[Slides]](https://explainml-tutorial.github.io/assets/files/explainml-tutorial-neurips20.pdf).
4. Generative Causal Explanations for Graph Neural Networks (ICML 2021)[[Paper]](https://proceedings.mlr.press/v139/lin21d/lin21d.pdf)[[Code]](https://github.com/wanyu-lin/ICML2021-Gem).
5. Towards Self-Explainable Graph Neural Network (CIKM 2021)[[Paper]](https://dl.acm.org/doi/pdf/10.1145/3459637.3482306?casa_token=z8ORG8cjfd8AAAAA:qUxGX52WexzY3Sh8WhvI1WMQYPuyUlvGzOxN3V1ZOzg8ZDrpsMzXO5HMwfgrLLgoHamwvMd3yDuS). 
6. Interpretable Machine Learning for Privacy-Preserving Pervasive Systems (IEEE Pervasive Computing)[[Paper]](https://ieeexplore.ieee.org/document/8962339).
7. Hard Masking for Explaining Graph Neural Networks (ICLR 2021)[[Paper]](https://openreview.net/forum?id=uDN8pRAdsoC). 
8. Interpretable and Generalizable Graph Learning via Stochastic Attention Mechanism (ICML 2022)[[Paper]](https://arxiv.org/abs/2201.12987).
9. Interpretability in Graph Neural Networks (Book 2022)[[Paper]](https://graph-neural-networks.github.io/static/file/chapter7.pdf).




