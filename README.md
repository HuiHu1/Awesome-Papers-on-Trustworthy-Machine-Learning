This repository aims to collect awesome papers or talks on trustworthy machine learning (including paper links, and code links).

#### Survey
1. When Machine Learning Meets Privacy: A Survey and Outlook (ACM Computing 2020) [[Paper]](https://arxiv.org/pdf/2011.11819.pdf).
2. A Survey on Privacy in Social Media: Identification, Mitigation, and Applications (ACM Transactions on Data Science 2020) [[Paper]](https://dl.acm.org/doi/pdf/10.1145/3343038).
3. A Survey on Security Threats and Defensive techniques of Machine Learning a data driven pespective (IEEE access 2018) [[Paper]](https://ieeexplore.ieee.org/abstract/document/8290925). 
4. Security of Neural Networks from Hardware Perspective: A Survey and Beyond (ASP-DAC 2021) [[Paper]](https://ieeexplore.ieee.org/abstract/document/9371637?casa_token=mjuDN_p4zlEAAAAA:1M--ahNOyo5OILtsqSFoycdzTqWqJg44fgFFTtyxNMaWG5mHrxRYaw9jbXc5ffUhpIVJBWLraw).
5. Trustworthy Graph Learning: Reliability, Explainability, and Privacy Protection (KDD 2022) [[Paper]](https://dl.acm.org/doi/pdf/10.1145/3534678.3542597?casa_token=pwDMMKIOSJUAAAAA:nN-GrlX_rUS-9RpmZv6Y0kwp3ZNV8X2GTWtBr_DW0S93tG8IafiRxRKGktW4i1ShH8hDwzUw-X8c).
6. Differential Privacy and Machine Learning - a Survey and Review (arXiv preprint) [[Paper]](https://arxiv.org/pdf/1412.7584.pdf). 

#### Fairness
1. On Structural Explanation of Bias in Graph Neural Networks (KDD 2022) [[Paper]](https://arxiv.org/pdf/2206.12104.pdf)[[Code]](https://github.com/yushundong/REFEREE).
2. Avoiding Biases due to Similarity Assumptions in Node Embeddings (KDD 2022) [[Paper]](https://faculty.mccombs.utexas.edu/deepayan.chakrabarti/mywww/papers/kdd22-avoiding.pdf).
3. Learning Fair Representation via Distributional Contrastive Disentanglement (KDD 2022) [[Paper]](https://dl.acm.org/doi/pdf/10.1145/3534678.3539232?casa_token=JaW7DTi1U9gAAAAA:Vcck-pl6AK_9-hbuMe3qfTkjPx4Mal0jD4VvdHcYKYCxbuEkshkrUpb9J1wXZjfD5FWwe8Af8XTa).
4. Algorithmic Fairness on Graphs: Methods and Trends (KDD 2022) [[Paper]](https://dl.acm.org/doi/abs/10.1145/3534678.3542599).
5. Algorithmic Fairness Verification with Graphical Models (AAAI 2022) [[Paper]](https://www.aaai.org/AAAI22Papers/AAAI-4695.GhoshB.pdf).
6. Improving Fairness in Graph Neural Networks via Mitigating Sensitive Attribute Leakage (KDD 2022) [[Paper]](https://arxiv.org/pdf/2206.03426.pdf)[[Code]](https://github.com/YuWVandy/FairVGNN).
7. EDITS: Modeling and Mitigating Data Bias for Graph Neural Networks (WWW 2022) [[Paper]](https://arxiv.org/pdf/2108.05233.pdf)[[Code]](https://github.com/yushundong/EDITS).
8. Achieving Fairness at No Utility Cost via Data Reweighing with Influence (ICML 2022) [[Paper]](https://arxiv.org/pdf/2202.00787.pdf)[[Code]](https://github.com/brandeis-machine-learning/influence-fairness).
9. Debiasing Graph Neural Networks via Learning Disentangled Causal Substructure (NeurIPS 2022) [[Paper]](https://arxiv.org/pdf/2209.14107.pdf)[[Code]](https://github.com/googlebaba/DisC).
10. Self-Supervised Fair Representation Learning without Demographics (NeurIPS 2022) [[Paper]](https://openreview.net/pdf?id=7TGpLKADODE).
11. Pushing the limits of fairness impossibility: Who's the fairest of them all? (NeurIPS 2022) [[Paper]](https://openreview.net/pdf?id=bot35zOudq).
12. Uncovering the Structural Fairness in Graph Contrastive Learning (NeurIPS 2022) [[Paper]](https://openreview.net/pdf?id=RJemsN3V_kt).
13. Self-Supervised Fair Representation Learning without Demographics (NeurIPS 2022) [[Paper]](https://openreview.net/pdf?id=7TGpLKADODE).
14. Flexibly Fair Representation Learning by Disentanglement (ICML 2019) [[Paper]](https://arxiv.org/pdf/1906.02589.pdf).

#### Privacy (Attacks and Defenses)
1. DICE: Domain-attack Invariant Causal Learning for Improved Data Privacy Protection and Adversarial Robustness (KDD 2022) [[Paper]](https://dl.acm.org/doi/abs/10.1145/3534678.3539242).
2. PrivateSNN: Privacy-Preserving Spiking Neural Networks (AAAI 2022) [[Paper]](https://arxiv.org/abs/2104.03414).
3. Subspace Differential Privacy (AAAI 2022) [[Paper]](https://arxiv.org/abs/2108.11527).
4. Masked Autoencoders Are Scalable Vision Learners (CVPR 2022) [[Paper]](https://openaccess.thecvf.com/content/CVPR2022/papers/He_Masked_Autoencoders_Are_Scalable_Vision_Learners_CVPR_2022_paper.pdf).
5. Information Obfuscation of Graph Neural Networks (ICML 2021) [[Paper]](https://arxiv.org/pdf/2009.13504.pdf).
6. How Does Data Augmentation Affect Privacy in Machine Learning? (AAAI 2021) [[Paper]](https://arxiv.org/pdf/2007.10567.pdf).
7. Graph Embedding for Recommendation against Attribute Inference Attacks (WWW 2021) [[Paper]](https://arxiv.org/pdf/2101.12549.pdf)).
8. Adversarial Attacks on Graph Neural Networks via Meta Learning (ICLR 2019) [[Paper]](https://arxiv.org/pdf/1902.08412.pdf) [[Code]](https://github.com/danielzuegner/gnn-meta-attack).
9. FaceMAE: Privacy-Preserving Face Recognition via Masked Autoencoders (ICLR 2023) [[Paper]](https://arxiv.org/pdf/2205.11090.pdf) [[Code]](https://github.com/kaiwang960112/FaceMAE).
10. GraphMAE: Self-Supervised Masked Graph Autoencoders (KDD 2022) [[Paper]](https://arxiv.org/pdf/2205.10803.pdf) [[Code]](https://github.com/THUDM/GraphMAE).
11. ConfounderGAN: Protecting Image Data Privacy with Causal Confounder (NeurIPS 2022) [[Paper]](https://openreview.net/pdf?id=XxmOKCt8dO9).
12. Alleviating Privacy Attacks via Causal Learning (ICML 2020) [[Paper]](http://proceedings.mlr.press/v119/tople20a/tople20a.pdf).

#### Interpretability
1. Interpretable and Generalizable Graph Learning via Stochastic Attention Mechanism (ICML 2022) [[Paper]](https://arxiv.org/abs/2201.12987).
2. Hard Masking for Explaining Graph Neural Networks (ICLR 2021) [[Paper]](https://openreview.net/forum?id=uDN8pRAdsoC). 
3. Interpretability in Graph Neural Networks (Book 2022) [[Paper]](https://graph-neural-networks.github.io/static/file/chapter7.pdf).
4. Interpretable Machine Learning for Privacy-Preserving Pervasive Systems (IEEE Pervasive Computing) [[Paper]](https://ieeexplore.ieee.org/document/8962339).
5. Concept Whitening for Interpretable Image Recognition (Nature Machine Intelligence 2020) [[Paper]](https://arxiv.org/pdf/2002.01650.pdf,https://github.com/danielzuegner/gnn-meta-attack).
6. Explaining Machine Learning Predictions: State-of-the-art, Challenges, Opportunities (NeurIPS 2020) [[Slides]](https://explainml-tutorial.github.io/assets/files/explainml-tutorial-neurips20.pdf).
7. GNNExplainer: Generating Explanations for Graph Neural Networks (NeurIPS 2019) [[Paper]](https://arxiv.org/pdf/1903.03894.pdf)[[Code]](https://github.com/RexYing/gnn-model-explainer).
8. Generative Causal Explanations for Graph Neural Networks (ICML 2021) [[Paper]](https://proceedings.mlr.press/v139/lin21d/lin21d.pdf).
